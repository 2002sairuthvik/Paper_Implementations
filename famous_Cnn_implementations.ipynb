{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4zaIHjrfRUaRaL9Xz8Rzp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "JKzyzz8ohoem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_16 = [64,64,'M',128,128,'M',256,256,'M',512,512,512,'M',512,512,512,'M']\n",
        "#then flatten 4096x4096x1000 Linear layers\n",
        "\n",
        "class VGG_net(nn.Module):\n",
        "  def __init__(self, in_channels=3,num_classes=1000):\n",
        "    super(VGG_net, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.conv_layers = self.create_conv_layers(VGG_16)\n",
        "    self.fcs = nn.Sequential(\n",
        "        nn.Linear(512*7*7,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv_layers(x)\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.fcs(x)\n",
        "    return x\n",
        "\n",
        "  def create_conv_layers(self,architecture):\n",
        "    layers = []\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for x in architecture:\n",
        "      if type(x) == int:\n",
        "        out_channels = x\n",
        "\n",
        "        layers += [nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=(3,3),stride=1,padding=1)]\n",
        "        layers += [nn.BatchNorm2d(x)]\n",
        "        layers += [nn.ReLU()]\n",
        "        in_channels = x\n",
        "      elif x == 'M':\n",
        "        layers += [nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))]\n",
        "\n",
        "    return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "NpwRMkhklSmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VGG_net(in_channels=3,num_classes=1000).to(device)\n",
        "print(model)\n",
        "x = torch.randn(1,3,224,224).to(device)\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "id": "OsPSK6WVn9LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "tC5BOCLeoNcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(nn.Module):\n",
        "  def __init__(self,in_channels=3,num_classes=1000):\n",
        "    super(GoogleNet,self).__init__()\n",
        "    self.conv1 = conv_block(in_channels=in_channels,out_channels=64,kernel_size=(7,7),stride=(2,2),padding=(3,3))\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    self.conv2 = conv_block(64,192,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    #in_channels,out_1x1,red_3x3,out_3x3,red_5x5,out_5x5,out_1x1pool\n",
        "    self.inception3a = Inception_block(192,64,96,128,16,32,32)\n",
        "    self.inception3b = Inception_block(256,128,128,192,32,96,64)\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    self.inception4a = Inception_block(480,192,96,208,16,48,64)\n",
        "    self.inception4b = Inception_block(512,160,112,224,24,64,64)\n",
        "    self.inception4c = Inception_block(512,128,128,256,24,64,64)\n",
        "    self.inception4d = Inception_block(512,112,144,288,32,64,64)\n",
        "    self.inception4e = Inception_block(528,256,160,320,32,128,128)\n",
        "    self.maxpool4 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    self.inception5a = Inception_block(832,256,160,320,32,128,128)\n",
        "    self.inception5b = Inception_block(832,384,192,384,48,128,128)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7,stride=1)\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.fc1 = nn.Linear(1024,1000)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x = self.inception3a(x)\n",
        "    x = self.inception3b(x)\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x = self.inception4a(x)\n",
        "    x = self.inception4b(x)\n",
        "    x = self.inception4c(x)\n",
        "    x = self.inception4d(x)\n",
        "    x = self.inception4e(x)\n",
        "    x = self.maxpool4(x)\n",
        "\n",
        "    x = self.inception5a(x)\n",
        "    x = self.inception5b(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Inception_block(nn.Module):\n",
        "  def __init__(self,in_channels,out_1x1,red_3x3,out_3x3,red_5x5,out_5x5,out_1x1pool):\n",
        "    super(Inception_block,self).__init__()\n",
        "    self.branch1 = conv_block(in_channels,out_1x1,kernel_size=1)\n",
        "    self.branch2 = nn.Sequential(\n",
        "        conv_block(in_channels,red_3x3,kernel_size=1),\n",
        "        conv_block(red_3x3,out_3x3,kernel_size=3,padding=1))\n",
        "    self.branch3 = nn.Sequential(\n",
        "        conv_block(in_channels,red_5x5,kernel_size=1),\n",
        "        conv_block(red_5x5,out_5x5,kernel_size=5,padding=2))\n",
        "    self.branch4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
        "        conv_block(in_channels,out_1x1pool,kernel_size=1))\n",
        "\n",
        "  def forward(self,x):\n",
        "    return torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,**kwargs):\n",
        "    super(conv_block,self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv2d(in_channels,out_channels,**kwargs) #kernel size = (1,1)(3,3)(5,5)\n",
        "    self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.relu(self.batchnorm(self.conv(x)))\n"
      ],
      "metadata": {
        "id": "_ymbejDJvhRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3,3,224,224)\n",
        "model = GoogleNet()\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "id": "cssvz2wLzmUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels,out_channels,identity_downsample=None,stride=1):\n",
        "    super(block,self).__init__()\n",
        "    self.expansion = 4\n",
        "    self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=stride,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv3 = nn.Conv2d(out_channels,out_channels*self.expansion,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.identity_downsample = identity_downsample\n",
        "\n",
        "  def forward(self,x):\n",
        "    identity = x\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    if self.identity_downsample is not None:\n",
        "      identity = self.identity_downsample(identity)\n",
        "\n",
        "    x += identity\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self,block,layers,image_channels,num_classes):\n",
        "    super(ResNet,self).__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv1 = nn.Conv2d(image_channels,64,kernel_size=7,stride=2,padding=3)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "\n",
        "    #ResNet layers\n",
        "    self.layer1 = self._make_layer(block,layers[0],out_channels=64,stride=1)\n",
        "    self.layer2 = self._make_layer(block,layers[1],out_channels=128,stride=2)\n",
        "    self.layer3 = self._make_layer(block,layers[2],out_channels=256,stride=2)\n",
        "    self.layer4 = self._make_layer(block,layers[3],out_channels=512,stride=2)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512*4,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,num_residual_blocks,out_channels,stride):\n",
        "    identity_downsample = None\n",
        "    layers = []\n",
        "\n",
        "    if stride != 1 or self.in_channels != out_channels*4:\n",
        "      identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels,out_channels*4,kernel_size=1,stride=stride),\n",
        "                                        nn.BatchNorm2d(out_channels*4))\n",
        "\n",
        "    layers.append(block(self.in_channels,out_channels,identity_downsample,stride))\n",
        "    self.in_channels = out_channels*4\n",
        "\n",
        "    for i in range(num_residual_blocks-1):\n",
        "      layers.append(block(self.in_channels,out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet50(img_channels=3,num_classes=1000):\n",
        "  return ResNet(block,[3,4,6,3],img_channels,num_classes)\n",
        "\n",
        "def ResNet101(img_channels=3,num_classes=1000):\n",
        "  return ResNet(block,[3,4,23,3],img_channels,num_classes)\n",
        "\n",
        "def ResNet152(img_channels=3,num_classes=1000):\n",
        "  return ResNet(block,[3,8,36,3],img_channels,num_classes)\n",
        "\n",
        "def test():\n",
        "  net = ResNet50()\n",
        "  x = torch.rand(2,3,224,224)\n",
        "  y = net(x)\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "ZiLWVOkd0EJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import (\n",
        "    DataLoader,\n",
        ")  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "import torchvision\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = 3\n",
        "num_classes = 10\n",
        "learning_rate = 3e-4 # karpathy's constant\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import sys\n",
        "#load the pretrain model and modify it\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.avgpool = Identity()\n",
        "model.classifier = nn.Sequential(nn.Linear(512,10),nn.ReLU(),nn.Linear(100,10))\n",
        "model.to(device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "\n",
        "# Hyperparameters\n",
        "num_classes = 10\n",
        "learning_rate = 3e-4\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Data transforms: resize to 224x224, convert to 3 channels, tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 2. Load Data\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=True, transform=transform, download=True\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=False, transform=transform, download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 3. Load pre-trained VGG16 and modify classifier\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "for param in model.features.parameters():  # Only freeze feature extractor\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier: VGG16 expects input of size 25088 (512*7*7) after avgpool for 224x224 images\n",
        "model.avgpool = Identity()\n",
        "model.classifier = nn.Sequential(nn.Linear(512,10),nn.ReLU(),nn.Linear(100,10))\n",
        "model.to(device)\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(512 * 7 * 7, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, num_classes)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# 4. Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)  # Only train classifier\n",
        "\n",
        "# 5. Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 6. Accuracy check\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum().item()\n",
        "            num_samples += predictions.size(0)\n",
        "    model.train()\n",
        "    return num_correct / num_samples\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples\n",
        "\n",
        "\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ],
      "metadata": {
        "id": "xRKXcfcK70CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbcHxmHq_uxr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}